{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import keras.preprocessing.sequence as sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzdata=np.load(\"data.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=npzdata['data']\n",
    "labels=npzdata['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=150\n",
    "data=sq.pad_sequences(data,maxlen=maxlen,padding='post',truncating='post',dtype='float64')\n",
    "data=data.reshape(data.shape[0],data.shape[1],1)\n",
    "dict_label={}\n",
    "n=0\n",
    "set_labels=list(set(labels))\n",
    "for l in set_labels:\n",
    "    dict_label[l]=n\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_new=[]\n",
    "for l in labels:\n",
    "    labels_new.append(dict_label[l])\n",
    "label_1=np_utils.to_categorical(labels_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(data,labels,batch_size=32):\n",
    "    nb_instances = data.shape[0]\n",
    "    nb_classes = labels.shape[1]\n",
    "    sample_shape = data[0].shape\n",
    "    batch_data_shape = tuple([batch_size] + list(sample_shape))\n",
    "    batch_label_shape = (batch_size, nb_classes)\n",
    "    print(batch_data_shape)\n",
    "    print(batch_label_shape)\n",
    "    # Infinite loop\n",
    "    while True:\n",
    "        # Generate an exploration order\n",
    "        indices = np.arange(nb_instances)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        # Generate batches\n",
    "        imax = int(len(indices) / batch_size)\n",
    "        for i in range(imax):\n",
    "            # Form a batch\n",
    "            x = np.empty(batch_data_shape)\n",
    "            y = np.empty(batch_label_shape)\n",
    "            for j, k in enumerate(indices[i * batch_size: (i + 1) * batch_size]):\n",
    "                x[j] = data[k]\n",
    "                y[j] = labels[k]\n",
    "            if x.shape != batch_data_shape:\n",
    "                print(x.shape)\n",
    "                exit(0)\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, x_test, Y_train, y_test = model_selection.train_test_split(data, label_1, test_size=0.15)\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(X_train, Y_train, test_size=0.18)\n",
    "\n",
    "trainGen=generateData(x_train,y_train)\n",
    "valGen=generateData(x_val,y_val)\n",
    "testGen=generateData(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Dropout,Permute,Lambda,RepeatVector,Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Input,multiply\n",
    "from keras.models import *\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length=maxlen\n",
    "input_dim=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(input_length, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_activitions=LSTM(units=128,activation='tanh',recurrent_activation='hard_sigmoid',return_sequences=True,dropout=0.2)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention= Permute((2, 1))(lstm_activitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = Dense(input_length, activation='softmax')(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(attention)\n",
    "attention = RepeatVector(input_dim)(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_probs = Permute((2, 1), name='attention_vec')(attention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_attention_mul  = multiply([lstm_activitions, a_probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes=label_1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_activations_2 = LSTM(units=128,activation='tanh',recurrent_activation='hard_sigmoid',return_sequences=True,dropout=0.2)(output_attention_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_2= Permute((2, 1))(lstm_activations_2)\n",
    "attention_2 = Dense(input_length, activation='softmax')(attention_2)\n",
    "attention_2 = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction_2')(attention_2)\n",
    "attention_2 = RepeatVector(input_dim)(attention_2)\n",
    "a_probs_2 = Permute((2, 1), name='attention_vec_2')(attention_2)\n",
    "output_attention_mul  = multiply([lstm_activations_2, a_probs_2])\n",
    "ouputs=Flatten()(output_attention_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=Dense(nb_classes,activation='softmax',name='output')(ouputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=[inputs],outputs=[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 150, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 150, 128)     66560       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 128, 150)     0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 150)     22650       permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dim_reduction (Lambda)          (None, 150)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 1, 150)       0           dim_reduction[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 150, 1)       0           repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 150, 128)     0           lstm_1[0][0]                     \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 150, 128)     131584      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 128, 150)     0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128, 150)     22650       permute_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dim_reduction_2 (Lambda)        (None, 150)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_4 (RepeatVector)  (None, 1, 150)       0           dim_reduction_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec_2 (Permute)       (None, 150, 1)       0           repeat_vector_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 150, 128)     0           lstm_2[0][0]                     \n",
      "                                                                 attention_vec_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 19200)        0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 101)          1939301     flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,182,745\n",
      "Trainable params: 2,182,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=RMSprop(lr=0.001,decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=optimizer,metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 150, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 150, 128)     66560       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 128, 150)     0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 150)     22650       permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dim_reduction (Lambda)          (None, 150)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 1, 150)       0           dim_reduction[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 150, 1)       0           repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 150, 128)     0           lstm_1[0][0]                     \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 150, 128)     131584      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 128, 150)     0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128, 150)     22650       permute_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dim_reduction_2 (Lambda)        (None, 150)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_4 (RepeatVector)  (None, 1, 150)       0           dim_reduction_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec_2 (Permute)       (None, 150, 1)       0           repeat_vector_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 150, 128)     0           lstm_2[0][0]                     \n",
      "                                                                 attention_vec_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 19200)        0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 101)          1939301     flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,182,745\n",
      "Trainable params: 2,182,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "(32, 150, 1)\n",
      "(32, 101)\n",
      "(32, 150, 1)\n",
      "(32, 101)\n",
      "1196/5445 [=====>........................] - ETA: 36:45 - loss: 4.2513 - acc: 0.0308"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(generator=trainGen,steps_per_epoch=x_train.shape[0]//32,validation_data=valGen,validation_steps=x_val.shape[0]//32,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
